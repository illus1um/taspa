# Логика ТАСПА: направления, скрапинг, аналитика и импорт

Документ для обсуждения и согласования логики платформы ТАСПА (аналитическая платформа мониторинга соцсетей по религиозным направлениям).

---

## 1. Направления (Directions)

**Суть:** Направления — это категории мониторинга (например: мадхал, немадхал, қмбд и т.д.). У каждого направления есть список **источников** по каждой соцсети: паблики/группы ВК, аккаунты Instagram, аккаунты TikTok.

### Текущая модель в БД

| Сущность | Описание |
|----------|----------|
| `directions` | id, name (название направления) |
| `direction_sources` | Связь направление → источник: `direction_id`, `source_type` (vk_group \| instagram_account \| tiktok_account), `source_identifier` (id группы, username и т.д.) |

**Источники** — это «что скрапить»: идентификаторы групп ВК, юзернеймы Instagram/TikTok. Они задаются админом вручную или импортируются.

### Итоговая логика

- Один **направление** может иметь много источников в разных соцсетях.
- По каждому направлению отдельно считаем аналитику и отдельно можем запускать скрапинг по каждой соцсети (VK / Instagram / TikTok).

**Вопросы для уточнения:**

- Нужна ли иерархия направлений (поднаправления) или плоский список достаточно?
- Нужно ли хранить «описание» или «код» направления (помимо имени)?

---

## 2. Скрапинг

**Цель:** Сбор данных (пользователи, источники пропаганды, контент) по религиозным направлениям в ВК, Instagram, TikTok по требованию заказчика.

### Текущая логика

1. **Оркестратор** (`scraping-orchestrator`):
   - Разработчик создаёт задачу: **направление** + **сервис** (vk / instagram / tiktok).
   - В БД создаётся `scrape_job` (service_name, direction_id, status).
   - Сообщение публикуется в RabbitMQ (exchange `scrape.jobs`).

2. **Скраперы** (vk-scraper, instagram-scraper, tiktok-scraper):
   - Должны подписаться на очередь, получить `job_id`, `direction_id`, `service_name`.
   - По `direction_id` взять из БД список источников для данной соцсети из `direction_sources` (WHERE direction_id = ? AND source_type = ?).
   - Обойти каждый источник, собрать данные.
   - Записать результат в соответствующие таблицы:
     - VK: `vk_groups`, `vk_members`
     - Instagram: `instagram_accounts`, `instagram_users`
     - TikTok: `tiktok_accounts`, `tiktok_users`
   - Обновить `scrape_job` (status, started_at, finished_at), писать логи в `scrape_logs`.

3. **Связь источников и скрапленных данных:**
   - `direction_sources` — «что скрапить» (идентификатор без метаданных).
   - `vk_groups` / `instagram_accounts` / `tiktok_accounts` — уже скрапленные сущности (с name, members_count, url, scraped_at и т.д.), привязаны к `direction_id`.
   - При скрапе: для каждого `source_identifier` создаётся или обновляется запись в соответствующей таблице групп/аккаунтов и заполняются участники/подписчики.

**Вопросы для уточнения:**

- Скраперы сейчас реально читают `direction_sources` и пишут в БД или только заглушки?
- Нужен ли «инкрементальный» скрап (только новые/изменённые) или каждый запуск — полный обход?
- Нужно ли хранить контент (посты, комментарии) или только пользователей и метаданные источников?

---

## 3. Аналитика

**Цель:** Выбор направления и просмотр аналитики по этому направлению, в разрезе соцсети (VK / Instagram / TikTok).

### Текущая реализация

- **Фронт:** Маршрут `/analytics/:platform` (vk | instagram | tiktok). Пользователь выбирает направление (select) и платформу (табы/URL).
- **Бэкенд (analytics-service):** Все эндпоинты принимают `direction_id` и возвращают данные по всем данным этого направления в соответствующей соцсети:
  - VK: summary, gender, universities, schools, timeline, groups, search по участникам.
  - Instagram: accounts, users по направлению.
  - TikTok: accounts, users по направлению.

Итог: аналитика уже «в разрезе направления». Платформа на фронте переключает только отображение (табы); данные по направлению для каждой соцсети уже разделены (разные эндпоинты и таблицы).

**Возможные доработки:**

- Явный query-параметр `platform` в API и фильтрация на бэкенде (если понадобится один общий эндпоинт «сводка по направлению и платформе»).
- Агрегаты «по всем соцсетям» для направления (общее количество учётных записей, источников и т.д.).
- Регион: сейчас в данных есть поля location; при необходимости — фильтр аналитики по региону.

---

## 4. Импорт скрапленных данных (JSON / CSV)

**Цель:** Загрузка уже собранных снаружи данных (JSON или CSV) в систему, чтобы не скрапить вручную или подтянуть исторические данные.

### Уже есть

- **Импорт VK CSV** (`POST /scrape/import/vk-csv`):
  - Параметры: `direction_id`, файл CSV.
  - Ожидаемые колонки: VK_ID, Имя, Фамилия, Пол, Группа (идентификатор группы).
  - Логика: для направления создаётся/обновляется `vk_groups` по полю «Группа», участники пишутся в `vk_members`. Обновляется `members_count`, `scraped_at`.

### Предлагаемое расширение

#### 4.1. Единый формат JSON для импорта по направлению

Один файл может содержать данные по одному направлению и одной соцсети (или по всем трём).

**Вариант структуры (пример):**

```json
{
  "direction_id": 1,
  "platform": "vk",
  "sources": [
    {
      "source_identifier": "club123456",
      "name": "Название группы",
      "members_count": 12450
    }
  ],
  "users": [
    {
      "source_identifier": "club123456",
      "vk_user_id": "12345",
      "full_name": "Имя Фамилия",
      "gender": "male",
      "university": "КазНУ",
      "school": "Школа №1"
    }
  ]
}
```

Для Instagram/TikTok — аналогично: `platform: "instagram"` / `"tiktok"`, в `users` поля username, url, bio, location, followers_count и т.д., привязка к источнику по `source_identifier` (username канала/аккаунта).

**Плюсы:** один эндпоинт, одна схема (с полем `platform`), можно импортировать большие объёмы из скриптов.

#### 4.2. Отдельные эндпоинты по платформам (как сейчас VK CSV)

- `POST /scrape/import/vk-csv` — оставить как есть (для таблиц из Excel/CSV).
- `POST /scrape/import/instagram-csv` и `POST /scrape/import/instagram-json` — по аналогии с VK: направление + файл, создание/обновление `instagram_accounts` и `instagram_users`.
- То же для TikTok: `tiktok-csv`, `tiktok-json`.

Форматы CSV для Instagram/TikTok можно зафиксировать (колонки: channel_username, user_username, url, bio, location, followers_count и т.д.).

#### 4.3. Синхронизация с direction_sources

При импорте (CSV или JSON) целесообразно:

- Если создаётся новая группа/аккаунт (по `source_identifier`), добавлять запись в `direction_sources` с соответствующим `source_type`, чтобы при следующем скрапе этот источник не терялся.
- Либо явно считать: «импорт только пополняет данные; список источников для скрапа ведётся только из админки». Тогда при импорте только вставляем в `vk_groups`/`vk_members` и т.д., без изменения `direction_sources`.

Рекомендация: при импорте **добавлять** в `direction_sources` отсутствующий источник (direction_id + source_type + source_identifier), чтобы направление и скрап оставались согласованными.

---

## 5. Краткое резюме

| Область | Состояние | Действия |
|---------|-----------|----------|
| Направления | Реализованы: directions + direction_sources по трём типам | Уточнить необходимость поднаправлений и доп. полей |
| Скрапинг | Оркестратор + jobs + логи; импорт VK CSV есть | Проверить, что скраперы читают direction_sources и пишут в БД; определиться с контентом и инкрементом |
| Аналитика | По direction_id и платформе (табы на фронте) | При необходимости — общий эндпоинт «направление + платформа», агрегаты по региону |
| Импорт | VK CSV | Добавить JSON-импорт (общий или по платформам), при желании — CSV для Instagram и TikTok; решить про обновление direction_sources при импорте |

После согласования форматов JSON/CSV и правил обновления `direction_sources` можно переходить к реализации эндпоинтов и обновлению фронта (например, выбор файла и платформы на странице разработчика).
